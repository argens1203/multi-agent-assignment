{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Demonstration of the API for the Stage 2 DQN Skeleton"
      ],
      "metadata": {
        "id": "CL0TGkjHLvw7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following two cells are only needed when working on CoLab. <br>Executing the next cell will ask for permission to access your gDrive. <br>You need to grant access to be able to use this code."
      ],
      "metadata": {
        "id": "Kjj2Xlwcq-W6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nm8KyiAqv97",
        "outputId": "b41281e0-e6c4-463f-8c96-feae26759d0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "moduleDirectory='/content/gdrive/My Drive/Colab Notebooks'\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next cell is only needed when working on CoLab."
      ],
      "metadata": {
        "id": "7oc6ZMBn0ILH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.insert(0,moduleDirectory)"
      ],
      "metadata": {
        "id": "5AhHqu7nrJpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, you obvisouly need to import the skeleton code"
      ],
      "metadata": {
        "id": "26ZUaHkUL8dD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from stage2skeletonv2 import *"
      ],
      "metadata": {
        "id": "aATxcjeOrKVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "API Demonstration"
      ],
      "metadata": {
        "id": "gQpQ1T_sHtID"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To set up the framework, call prepare_torch wihtout parameters, this yields a model object (the actual torch DQN, which you can but don't need to use later)."
      ],
      "metadata": {
        "id": "aEMyra_aMDJF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = prepare_torch()"
      ],
      "metadata": {
        "id": "esoJ3f6hHrfo"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A state description is a numpy float array of statespace size"
      ],
      "metadata": {
        "id": "KBHu0vXdMacC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "statespace_size=48"
      ],
      "metadata": {
        "id": "U90e66kJnpPi"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state=np.random.rand(1,statespace_size)"
      ],
      "metadata": {
        "id": "ImA1_kM4Ic5_"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get all Q values for a specific state call get_gvals with this state descriptor as the argument. This returns an array of floats (one Q value per action)"
      ],
      "metadata": {
        "id": "2RV7pKzfMhOx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  qvals = get_qvals(state)\n",
        "  print(qvals)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1c-QODaLIl8M",
        "outputId": "c493cbae-4633-4123-a14a-b03d54b1635c"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.04451853  0.12609628 -0.04068024  0.07884467]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you want only the maximum Q value for a state you can use get_maxQ instead. Note that this returns the float but as a torch tensor!"
      ],
      "metadata": {
        "id": "sXRZZs6FM0Ix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_maxQ(state)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvUnmCPWIvAP",
        "outputId": "a196250e-4346-4d53-a265-f1dccf2e2034"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1261, grad_fn=<MaxBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nevermind, you can compute wiht this tensor (almost) as if it were a normal float"
      ],
      "metadata": {
        "id": "D4zd3KY0NABu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "4*get_maxQ(state)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSXRov5SJrJb",
        "outputId": "f9e7cd29-6257-4f51-87a2-187c337af137"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.5044, grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To perform a learning step, you operate on a minibatch of (state, action, target) triplets. These triplets are passes to the function train_one_step in three separate parallel lists, like so:"
      ],
      "metadata": {
        "id": "GOOwx9gxNIeA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "state1=np.random.rand(1,statespace_size)\n",
        "state2=np.random.rand(1,statespace_size)"
      ],
      "metadata": {
        "id": "hsm4irAqKdZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "action1=action_ = np.random.randint(0,4)\n",
        "action2=action_ = np.random.randint(0,4)"
      ],
      "metadata": {
        "id": "Xg0LnLLiKxur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TD_target1 = 4*get_maxQ(state1)\n",
        "TD_target2 = 33+2.54*get_maxQ(state2)"
      ],
      "metadata": {
        "id": "jsfm4mPxK5pL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state=[state1,state2]\n",
        "actions=[action1,action2]\n",
        "targets=[TD_target1,TD_target2]"
      ],
      "metadata": {
        "id": "_4Q-9NoLLQlx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, you also need to pass the discount rate, which is just a float. Note that this is just a technicality as it is not longer used by this function. However, the API is still defined in this way (we may remove this in the next version)."
      ],
      "metadata": {
        "id": "O5f9J2TQNlk2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gamma=0.95"
      ],
      "metadata": {
        "id": "ACWeGE5jLahU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "current_loss = train_one_step(states, actions, targets, gamma)"
      ],
      "metadata": {
        "id": "immnHIUMJw1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This returns the current DQN loss, which you may but don't have to use for monitoring and debugging purposes."
      ],
      "metadata": {
        "id": "t8_T-kjIOiT9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "current_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aIzmSiZLd-u",
        "outputId": "c5ffe6c3-2050-4904-c12d-07af13c6629e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "555.565673828125"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, you need to copy the prediction model to the target model every now and then. Both models are handled automatically behind the scenes, but you decide on when this update happens using the update_target function."
      ],
      "metadata": {
        "id": "YEX91l1tOrLw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "update_target()"
      ],
      "metadata": {
        "id": "ZzZodjaSJ-0u"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}